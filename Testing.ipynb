{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import Callback, CSVLogger, TensorBoard\n",
    "from tensorflow.python.saved_model.loader_impl import parse_saved_model\n",
    "from tensorflow.keras.losses import MSE, MeanAbsoluteError, BinaryCrossentropy\n",
    "from modules.CustomLosses import LSSIM, L1AdversarialLoss, AdversarialLoss\n",
    "from modules.misc import ssim_metric, get_model\n",
    "from psnrb import psnrb\n",
    "from modules.DataMod import DataSet\n",
    "from modules.TrainingManager import KerasTrainingManager\n",
    "from os import environ\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPSNRB (target_imgs, degraded_imgs):\n",
    "    return -psnrb(target_imgs, degraded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_json_name = \"AutoEncoder-2.0-64x64.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = SGD(),\n",
    "    loss = LSSIM(),\n",
    "    metrics = [ssim_metric, psnrb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet().load_rafael_cifar_10_noise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleTrainingLogger(Callback):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 stop_fucntion: Callable[[list, str, Callable], bool],\n",
    "                 metric_name: str,\n",
    "                 dir_name: str = 'logs'\n",
    "                   ):\n",
    "        super(MultipleTrainingLogger, self).__init__()\n",
    "        \n",
    "        self.training_index: int \n",
    "        \n",
    "        self.per_epoch_batch_results: dict = {}\n",
    "        self.epoch_mean_results: dict = {}\n",
    "        self.all_batch_results: dict = {}\n",
    "\n",
    "        self.stop_function: Callable[[list, str, Callable], bool] = stop_fucntion\n",
    "        self.metric_name: str = metric_name\n",
    "        self.stoped_epoch: int = 0\n",
    "        self.training_stoped: bool = False\n",
    "\n",
    "        self.dir_name = dir_name\n",
    "    \n",
    "    # Geters\n",
    "\n",
    "    def get_optimizer_kwargs(self) -> dict: \n",
    "        return self.model.optimizer.get_config()\n",
    "\n",
    "    def get_model_name(self) -> str:\n",
    "        return self.model.name\n",
    "\n",
    "    def get_loss_kwargs(self) -> dict:\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Operations\n",
    "\n",
    "    def append_results(self, results_dict: dict, logs: dict):\n",
    "        \n",
    "        for metric_name, metric_value in logs.items():\n",
    "            \n",
    "            if not metric_name in results_dict:\n",
    "                results_dict[metric_name] = []\n",
    "            \n",
    "            results_dict[metric_name].append(metric_value)\n",
    "\n",
    "    def append_epoch_mean (self):\n",
    "\n",
    "        for metric_name, metric_array in self.per_epoch_batch_results.items():\n",
    "            \n",
    "            metric_epoch_mean =  np.mean(metric_array, axis = 0)\n",
    "            \n",
    "            if not metric_name in self.epoch_mean_results:\n",
    "                self.epoch_mean_results[metric_name] = []\n",
    "            \n",
    "            self.epoch_mean_results[metric_name].append(metric_epoch_mean)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Batch and epoch operations\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \n",
    "        # clean epoch data\n",
    "        self.per_epoch_batch_results: dict = {}\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        \n",
    "        self.append_results(self.per_epoch_batch_results, logs)\n",
    "        self.append_results(self.all_batch_results, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        self.append_epoch_mean()\n",
    "\n",
    "        self.model.stop_training = self.stop_function(self.epoch_mean_results, self.metric_name)\n",
    "        \n",
    "        self.stoped_epoch = epoch\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        return super().on_train_end(logs)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_fucntion (epoch_mean_results: dict, \n",
    "                   metric_name: str,\n",
    "                   best_metric_selector = max,\n",
    "                   min_percentual_variation = 0.02/100,\n",
    "                   observation_window_lenght = 7) -> bool: \n",
    "\n",
    "    if len(epoch_mean_results[metric_name]) < observation_window_lenght + 1:\n",
    "        return False\n",
    "    \n",
    "    best_window_result = best_metric_selector(epoch_mean_results[metric_name][-observation_window_lenght:])\n",
    "\n",
    "    best_result_outside_window = best_metric_selector(epoch_mean_results[metric_name][:-observation_window_lenght])\n",
    "\n",
    "    stop_signal = (best_window_result - best_result_outside_window)/best_result_outside_window < min_percentual_variation\n",
    "\n",
    "    return stop_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function blocking_efect_factor at 0x7fa4f6034e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function blocking_efect_factor at 0x7fa4f6034e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 61s 19ms/step - loss: 0.6443 - ssim_metric: 0.3557 - psnrb: 12.4331 - val_loss: 0.3930 - val_ssim_metric: 0.6070 - val_psnrb: 17.9490\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.3831 - ssim_metric: 0.6169 - psnrb: 17.3139 - val_loss: 0.3512 - val_ssim_metric: 0.6488 - val_psnrb: 18.0042\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.3413 - ssim_metric: 0.6587 - psnrb: 18.4481 - val_loss: 0.3205 - val_ssim_metric: 0.6795 - val_psnrb: 19.7731\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.3172 - ssim_metric: 0.6828 - psnrb: 19.2811 - val_loss: 0.3123 - val_ssim_metric: 0.6877 - val_psnrb: 19.1527\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.3028 - ssim_metric: 0.6972 - psnrb: 19.8660 - val_loss: 0.2939 - val_ssim_metric: 0.7061 - val_psnrb: 19.6578\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2922 - ssim_metric: 0.7078 - psnrb: 20.1871 - val_loss: 0.2798 - val_ssim_metric: 0.7202 - val_psnrb: 21.1024\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2826 - ssim_metric: 0.7174 - psnrb: 20.5499 - val_loss: 0.2786 - val_ssim_metric: 0.7214 - val_psnrb: 20.7575\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2747 - ssim_metric: 0.7253 - psnrb: 20.8744 - val_loss: 0.2692 - val_ssim_metric: 0.7308 - val_psnrb: 20.4854\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2679 - ssim_metric: 0.7321 - psnrb: 21.0880 - val_loss: 0.2631 - val_ssim_metric: 0.7369 - val_psnrb: 21.0261\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2611 - ssim_metric: 0.7389 - psnrb: 21.3069 - val_loss: 0.2556 - val_ssim_metric: 0.7444 - val_psnrb: 21.5998\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2553 - ssim_metric: 0.7447 - psnrb: 21.4719 - val_loss: 0.2545 - val_ssim_metric: 0.7455 - val_psnrb: 21.2378\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2507 - ssim_metric: 0.7493 - psnrb: 21.6102 - val_loss: 0.2455 - val_ssim_metric: 0.7545 - val_psnrb: 22.3711\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2469 - ssim_metric: 0.7531 - psnrb: 21.6468 - val_loss: 0.2410 - val_ssim_metric: 0.7590 - val_psnrb: 22.2938\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2416 - ssim_metric: 0.7584 - psnrb: 22.1180 - val_loss: 0.2416 - val_ssim_metric: 0.7584 - val_psnrb: 21.3598\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2387 - ssim_metric: 0.7613 - psnrb: 22.1078 - val_loss: 0.2320 - val_ssim_metric: 0.7680 - val_psnrb: 23.6389\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2348 - ssim_metric: 0.7652 - psnrb: 22.4125 - val_loss: 0.2298 - val_ssim_metric: 0.7702 - val_psnrb: 23.7505\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2323 - ssim_metric: 0.7677 - psnrb: 22.2922 - val_loss: 0.2269 - val_ssim_metric: 0.7731 - val_psnrb: 22.9801\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2296 - ssim_metric: 0.7704 - psnrb: 22.3617 - val_loss: 0.2251 - val_ssim_metric: 0.7749 - val_psnrb: 23.4668\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2275 - ssim_metric: 0.7725 - psnrb: 22.4124 - val_loss: 0.2240 - val_ssim_metric: 0.7760 - val_psnrb: 22.2199\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2250 - ssim_metric: 0.7750 - psnrb: 22.5365 - val_loss: 0.2174 - val_ssim_metric: 0.7826 - val_psnrb: 24.2296\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2227 - ssim_metric: 0.7773 - psnrb: 22.5638 - val_loss: 0.2233 - val_ssim_metric: 0.7767 - val_psnrb: 21.6246\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2213 - ssim_metric: 0.7787 - psnrb: 22.5280 - val_loss: 0.2151 - val_ssim_metric: 0.7849 - val_psnrb: 23.7174\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2189 - ssim_metric: 0.7811 - psnrb: 22.6909 - val_loss: 0.2144 - val_ssim_metric: 0.7856 - val_psnrb: 23.3155\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2177 - ssim_metric: 0.7823 - psnrb: 22.6360 - val_loss: 0.2137 - val_ssim_metric: 0.7863 - val_psnrb: 23.2171\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2158 - ssim_metric: 0.7842 - psnrb: 22.7423 - val_loss: 0.2105 - val_ssim_metric: 0.7895 - val_psnrb: 24.0220\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2137 - ssim_metric: 0.7863 - psnrb: 23.0018 - val_loss: 0.2179 - val_ssim_metric: 0.7821 - val_psnrb: 21.5518\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2128 - ssim_metric: 0.7872 - psnrb: 22.8876 - val_loss: 0.2115 - val_ssim_metric: 0.7885 - val_psnrb: 22.4766\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2111 - ssim_metric: 0.7889 - psnrb: 22.9345 - val_loss: 0.2112 - val_ssim_metric: 0.7888 - val_psnrb: 24.1867\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2099 - ssim_metric: 0.7901 - psnrb: 22.9991 - val_loss: 0.2159 - val_ssim_metric: 0.7841 - val_psnrb: 22.2180\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2084 - ssim_metric: 0.7916 - psnrb: 23.1469 - val_loss: 0.2113 - val_ssim_metric: 0.7887 - val_psnrb: 22.1307\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2079 - ssim_metric: 0.7921 - psnrb: 23.0437 - val_loss: 0.2091 - val_ssim_metric: 0.7909 - val_psnrb: 21.9616\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2072 - ssim_metric: 0.7928 - psnrb: 23.0130 - val_loss: 0.2043 - val_ssim_metric: 0.7957 - val_psnrb: 22.9728\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2059 - ssim_metric: 0.7941 - psnrb: 23.0818 - val_loss: 0.2076 - val_ssim_metric: 0.7924 - val_psnrb: 21.7620\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2047 - ssim_metric: 0.7953 - psnrb: 23.0736 - val_loss: 0.2062 - val_ssim_metric: 0.7938 - val_psnrb: 22.1901\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2035 - ssim_metric: 0.7965 - psnrb: 23.1314 - val_loss: 0.2114 - val_ssim_metric: 0.7886 - val_psnrb: 20.9962\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2028 - ssim_metric: 0.7972 - psnrb: 23.2763 - val_loss: 0.2081 - val_ssim_metric: 0.7919 - val_psnrb: 21.1763\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2014 - ssim_metric: 0.7986 - psnrb: 23.3726 - val_loss: 0.2012 - val_ssim_metric: 0.7988 - val_psnrb: 22.5965\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2007 - ssim_metric: 0.7993 - psnrb: 23.3750 - val_loss: 0.1980 - val_ssim_metric: 0.8020 - val_psnrb: 23.6170\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1999 - ssim_metric: 0.8001 - psnrb: 23.3434 - val_loss: 0.2007 - val_ssim_metric: 0.7993 - val_psnrb: 22.8249\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1994 - ssim_metric: 0.8006 - psnrb: 23.3861 - val_loss: 0.2001 - val_ssim_metric: 0.7999 - val_psnrb: 22.5409\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1984 - ssim_metric: 0.8016 - psnrb: 23.3114 - val_loss: 0.1967 - val_ssim_metric: 0.8033 - val_psnrb: 23.7083\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1981 - ssim_metric: 0.8019 - psnrb: 23.4866 - val_loss: 0.1975 - val_ssim_metric: 0.8025 - val_psnrb: 24.6013\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1973 - ssim_metric: 0.8027 - psnrb: 23.4831 - val_loss: 0.1971 - val_ssim_metric: 0.8029 - val_psnrb: 23.0216\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1962 - ssim_metric: 0.8038 - psnrb: 23.5764 - val_loss: 0.1932 - val_ssim_metric: 0.8068 - val_psnrb: 24.6645\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1958 - ssim_metric: 0.8042 - psnrb: 23.6321 - val_loss: 0.1965 - val_ssim_metric: 0.8035 - val_psnrb: 23.6791\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1957 - ssim_metric: 0.8043 - psnrb: 23.3978 - val_loss: 0.1932 - val_ssim_metric: 0.8068 - val_psnrb: 23.9599\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1943 - ssim_metric: 0.8057 - psnrb: 23.4828 - val_loss: 0.1917 - val_ssim_metric: 0.8083 - val_psnrb: 24.4359\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1940 - ssim_metric: 0.8060 - psnrb: 23.6230 - val_loss: 0.1961 - val_ssim_metric: 0.8039 - val_psnrb: 23.2108\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1932 - ssim_metric: 0.8068 - psnrb: 23.7326 - val_loss: 0.1952 - val_ssim_metric: 0.8048 - val_psnrb: 22.2388\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1936 - ssim_metric: 0.8064 - psnrb: 23.5094 - val_loss: 0.1909 - val_ssim_metric: 0.8091 - val_psnrb: 24.2885\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1914 - ssim_metric: 0.8086 - psnrb: 23.9342 - val_loss: 0.1880 - val_ssim_metric: 0.8120 - val_psnrb: 25.1794\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1915 - ssim_metric: 0.8085 - psnrb: 23.7631 - val_loss: 0.1878 - val_ssim_metric: 0.8122 - val_psnrb: 25.0666\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1904 - ssim_metric: 0.8096 - psnrb: 23.9398 - val_loss: 0.1877 - val_ssim_metric: 0.8123 - val_psnrb: 25.1978\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1907 - ssim_metric: 0.8093 - psnrb: 23.8589 - val_loss: 0.1922 - val_ssim_metric: 0.8078 - val_psnrb: 22.5128\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1903 - ssim_metric: 0.8097 - psnrb: 23.7901 - val_loss: 0.1869 - val_ssim_metric: 0.8131 - val_psnrb: 25.1135\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1890 - ssim_metric: 0.8110 - psnrb: 23.9900 - val_loss: 0.1917 - val_ssim_metric: 0.8083 - val_psnrb: 23.3434\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1894 - ssim_metric: 0.8106 - psnrb: 23.7424 - val_loss: 0.1851 - val_ssim_metric: 0.8149 - val_psnrb: 25.3253\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1892 - ssim_metric: 0.8108 - psnrb: 23.8178 - val_loss: 0.1847 - val_ssim_metric: 0.8153 - val_psnrb: 25.3172\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1878 - ssim_metric: 0.8122 - psnrb: 23.9750 - val_loss: 0.1897 - val_ssim_metric: 0.8103 - val_psnrb: 23.7181\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1874 - ssim_metric: 0.8126 - psnrb: 23.9738 - val_loss: 0.1867 - val_ssim_metric: 0.8133 - val_psnrb: 24.9918\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1877 - ssim_metric: 0.8123 - psnrb: 24.0687 - val_loss: 0.1896 - val_ssim_metric: 0.8104 - val_psnrb: 23.5250\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1873 - ssim_metric: 0.8127 - psnrb: 23.8047 - val_loss: 0.1851 - val_ssim_metric: 0.8149 - val_psnrb: 24.8135\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1870 - ssim_metric: 0.8130 - psnrb: 23.9233 - val_loss: 0.1845 - val_ssim_metric: 0.8155 - val_psnrb: 24.4727\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1865 - ssim_metric: 0.8135 - psnrb: 24.0275 - val_loss: 0.1866 - val_ssim_metric: 0.8134 - val_psnrb: 23.4364\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1862 - ssim_metric: 0.8138 - psnrb: 24.0011 - val_loss: 0.1907 - val_ssim_metric: 0.8093 - val_psnrb: 22.8674\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1851 - ssim_metric: 0.8149 - psnrb: 24.1803 - val_loss: 0.1835 - val_ssim_metric: 0.8165 - val_psnrb: 25.0222\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1854 - ssim_metric: 0.8146 - psnrb: 23.9209 - val_loss: 0.1849 - val_ssim_metric: 0.8151 - val_psnrb: 23.6904\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1846 - ssim_metric: 0.8154 - psnrb: 24.1093 - val_loss: 0.1821 - val_ssim_metric: 0.8179 - val_psnrb: 25.0549\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1840 - ssim_metric: 0.8160 - psnrb: 24.3273 - val_loss: 0.1882 - val_ssim_metric: 0.8118 - val_psnrb: 23.2163\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1845 - ssim_metric: 0.8155 - psnrb: 24.0215 - val_loss: 0.1806 - val_ssim_metric: 0.8194 - val_psnrb: 25.5396\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1841 - ssim_metric: 0.8159 - psnrb: 24.0150 - val_loss: 0.1838 - val_ssim_metric: 0.8162 - val_psnrb: 24.0476\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1831 - ssim_metric: 0.8169 - psnrb: 24.2128 - val_loss: 0.1870 - val_ssim_metric: 0.8130 - val_psnrb: 24.8780\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1829 - ssim_metric: 0.8171 - psnrb: 24.2403 - val_loss: 0.1820 - val_ssim_metric: 0.8180 - val_psnrb: 25.4129\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1828 - ssim_metric: 0.8172 - psnrb: 24.2589 - val_loss: 0.1850 - val_ssim_metric: 0.8150 - val_psnrb: 23.4968\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1829 - ssim_metric: 0.8171 - psnrb: 24.1392 - val_loss: 0.1813 - val_ssim_metric: 0.8187 - val_psnrb: 24.1690\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1827 - ssim_metric: 0.8173 - psnrb: 24.2185 - val_loss: 0.1817 - val_ssim_metric: 0.8183 - val_psnrb: 24.3760\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1820 - ssim_metric: 0.8180 - psnrb: 24.1584 - val_loss: 0.1824 - val_ssim_metric: 0.8176 - val_psnrb: 24.2809\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1819 - ssim_metric: 0.8181 - psnrb: 24.2656 - val_loss: 0.1878 - val_ssim_metric: 0.8122 - val_psnrb: 22.1953\n",
      "Epoch 79/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1810 - ssim_metric: 0.8190 - psnrb: 24.4401 - val_loss: 0.1828 - val_ssim_metric: 0.8172 - val_psnrb: 24.2305\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1816 - ssim_metric: 0.8184 - psnrb: 24.2557 - val_loss: 0.1811 - val_ssim_metric: 0.8189 - val_psnrb: 24.1424\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1814 - ssim_metric: 0.8186 - psnrb: 24.1999 - val_loss: 0.1803 - val_ssim_metric: 0.8197 - val_psnrb: 24.6038\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1809 - ssim_metric: 0.8191 - psnrb: 24.2663 - val_loss: 0.1797 - val_ssim_metric: 0.8203 - val_psnrb: 25.4836\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1798 - ssim_metric: 0.8202 - psnrb: 24.5188 - val_loss: 0.1799 - val_ssim_metric: 0.8201 - val_psnrb: 23.8218\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1803 - ssim_metric: 0.8197 - psnrb: 24.2426 - val_loss: 0.1794 - val_ssim_metric: 0.8206 - val_psnrb: 24.2504\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1803 - ssim_metric: 0.8197 - psnrb: 24.2433 - val_loss: 0.1806 - val_ssim_metric: 0.8194 - val_psnrb: 24.7831\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1791 - ssim_metric: 0.8209 - psnrb: 24.3696 - val_loss: 0.1798 - val_ssim_metric: 0.8202 - val_psnrb: 23.8580\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1795 - ssim_metric: 0.8205 - psnrb: 24.4957 - val_loss: 0.1789 - val_ssim_metric: 0.8211 - val_psnrb: 24.3531\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1795 - ssim_metric: 0.8205 - psnrb: 24.3496 - val_loss: 0.1770 - val_ssim_metric: 0.8230 - val_psnrb: 24.9989\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1789 - ssim_metric: 0.8211 - psnrb: 24.5059 - val_loss: 0.1776 - val_ssim_metric: 0.8224 - val_psnrb: 25.6162\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1788 - ssim_metric: 0.8212 - psnrb: 24.3776 - val_loss: 0.1790 - val_ssim_metric: 0.8210 - val_psnrb: 23.7529\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1787 - ssim_metric: 0.8213 - psnrb: 24.4718 - val_loss: 0.1762 - val_ssim_metric: 0.8238 - val_psnrb: 25.1284\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1781 - ssim_metric: 0.8219 - psnrb: 24.5383 - val_loss: 0.1781 - val_ssim_metric: 0.8219 - val_psnrb: 24.7716\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1788 - ssim_metric: 0.8212 - psnrb: 24.2345 - val_loss: 0.1799 - val_ssim_metric: 0.8201 - val_psnrb: 24.0334\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1781 - ssim_metric: 0.8219 - psnrb: 24.3588 - val_loss: 0.1787 - val_ssim_metric: 0.8213 - val_psnrb: 24.3681\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1783 - ssim_metric: 0.8217 - psnrb: 24.3661 - val_loss: 0.1788 - val_ssim_metric: 0.8212 - val_psnrb: 24.3020\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1780 - ssim_metric: 0.8220 - psnrb: 24.3945 - val_loss: 0.1846 - val_ssim_metric: 0.8154 - val_psnrb: 22.9491\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1774 - ssim_metric: 0.8226 - psnrb: 24.4494 - val_loss: 0.1835 - val_ssim_metric: 0.8165 - val_psnrb: 21.6664\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1774 - ssim_metric: 0.8226 - psnrb: 24.5251 - val_loss: 0.1779 - val_ssim_metric: 0.8221 - val_psnrb: 24.6230\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1777 - ssim_metric: 0.8223 - psnrb: 24.1703 - val_loss: 0.1775 - val_ssim_metric: 0.8225 - val_psnrb: 24.0731\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1767 - ssim_metric: 0.8233 - psnrb: 24.4938 - val_loss: 0.1799 - val_ssim_metric: 0.8201 - val_psnrb: 23.6429\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1769 - ssim_metric: 0.8231 - psnrb: 24.3324 - val_loss: 0.1771 - val_ssim_metric: 0.8229 - val_psnrb: 23.8530\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1768 - ssim_metric: 0.8232 - psnrb: 24.4738 - val_loss: 0.1760 - val_ssim_metric: 0.8240 - val_psnrb: 25.1729\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1761 - ssim_metric: 0.8239 - psnrb: 24.7342 - val_loss: 0.1766 - val_ssim_metric: 0.8234 - val_psnrb: 24.5039\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1760 - ssim_metric: 0.8240 - psnrb: 24.4671 - val_loss: 0.1761 - val_ssim_metric: 0.8239 - val_psnrb: 24.9316\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1761 - ssim_metric: 0.8239 - psnrb: 24.5278 - val_loss: 0.1752 - val_ssim_metric: 0.8248 - val_psnrb: 24.3339\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1760 - ssim_metric: 0.8240 - psnrb: 24.4742 - val_loss: 0.1741 - val_ssim_metric: 0.8259 - val_psnrb: 25.2335\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1760 - ssim_metric: 0.8240 - psnrb: 24.5950 - val_loss: 0.1795 - val_ssim_metric: 0.8205 - val_psnrb: 24.1146\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1756 - ssim_metric: 0.8244 - psnrb: 24.5911 - val_loss: 0.1835 - val_ssim_metric: 0.8165 - val_psnrb: 20.9381\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1757 - ssim_metric: 0.8243 - psnrb: 24.4757 - val_loss: 0.1749 - val_ssim_metric: 0.8251 - val_psnrb: 24.1616\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1758 - ssim_metric: 0.8242 - psnrb: 24.3484 - val_loss: 0.1741 - val_ssim_metric: 0.8259 - val_psnrb: 25.5278\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1750 - ssim_metric: 0.8250 - psnrb: 24.5815 - val_loss: 0.1800 - val_ssim_metric: 0.8200 - val_psnrb: 24.2329\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1747 - ssim_metric: 0.8253 - psnrb: 24.7008 - val_loss: 0.1743 - val_ssim_metric: 0.8257 - val_psnrb: 25.2850\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1743 - ssim_metric: 0.8257 - psnrb: 24.7272 - val_loss: 0.1734 - val_ssim_metric: 0.8266 - val_psnrb: 25.8929\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1748 - ssim_metric: 0.8252 - psnrb: 24.6721 - val_loss: 0.1747 - val_ssim_metric: 0.8253 - val_psnrb: 24.0384\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1746 - ssim_metric: 0.8254 - psnrb: 24.6274 - val_loss: 0.1735 - val_ssim_metric: 0.8265 - val_psnrb: 25.0728\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1748 - ssim_metric: 0.8252 - psnrb: 24.4578 - val_loss: 0.1749 - val_ssim_metric: 0.8251 - val_psnrb: 24.6492\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1739 - ssim_metric: 0.8261 - psnrb: 24.7383 - val_loss: 0.1740 - val_ssim_metric: 0.8260 - val_psnrb: 24.9330\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1738 - ssim_metric: 0.8262 - psnrb: 24.6474 - val_loss: 0.1733 - val_ssim_metric: 0.8267 - val_psnrb: 25.6704\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1734 - ssim_metric: 0.8266 - psnrb: 24.6660 - val_loss: 0.1739 - val_ssim_metric: 0.8261 - val_psnrb: 24.6958\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1739 - ssim_metric: 0.8261 - psnrb: 24.6269 - val_loss: 0.1716 - val_ssim_metric: 0.8284 - val_psnrb: 25.7516\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1729 - ssim_metric: 0.8271 - psnrb: 24.9934 - val_loss: 0.1778 - val_ssim_metric: 0.8222 - val_psnrb: 22.2244\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1733 - ssim_metric: 0.8267 - psnrb: 24.5941 - val_loss: 0.1768 - val_ssim_metric: 0.8232 - val_psnrb: 23.7208\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1733 - ssim_metric: 0.8267 - psnrb: 24.6945 - val_loss: 0.1734 - val_ssim_metric: 0.8266 - val_psnrb: 24.9978\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1730 - ssim_metric: 0.8270 - psnrb: 24.7765 - val_loss: 0.1754 - val_ssim_metric: 0.8246 - val_psnrb: 23.8875\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1730 - ssim_metric: 0.8270 - psnrb: 24.7748 - val_loss: 0.1720 - val_ssim_metric: 0.8280 - val_psnrb: 25.3138\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1727 - ssim_metric: 0.8273 - psnrb: 24.8988 - val_loss: 0.1726 - val_ssim_metric: 0.8274 - val_psnrb: 24.0569\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1730 - ssim_metric: 0.8270 - psnrb: 24.5758 - val_loss: 0.1770 - val_ssim_metric: 0.8230 - val_psnrb: 22.3927\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1727 - ssim_metric: 0.8273 - psnrb: 24.6974 - val_loss: 0.1713 - val_ssim_metric: 0.8287 - val_psnrb: 25.5332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa4f05b9130>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = MultipleTrainingLogger(stop_fucntion, \"ssim_metric\")\n",
    "model.fit(\n",
    "    x = dataset.x_train,\n",
    "    y = dataset.y_train,\n",
    "    batch_size = 50,\n",
    "    epochs = 500,\n",
    "    validation_data = (dataset.x_test, dataset.y_test),\n",
    "    callbacks = [callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "callback.epoch_mean_results[\"ssim_metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn\n",
    "from tensorflow.python.ops import nn_ops\n",
    "import tensorflow as tf\n",
    "\n",
    "def _ssim_helper(x, y, reducer, max_val, compensation=1.0, k1=0.01, k2=0.03):\n",
    "  r\"\"\"Helper function for computing SSIM.\n",
    "\n",
    "  SSIM estimates covariances with weighted sums.  The default parameters\n",
    "  use a biased estimate of the covariance:\n",
    "  Suppose `reducer` is a weighted sum, then the mean estimators are\n",
    "    \\mu_x = \\sum_i w_i x_i,\n",
    "    \\mu_y = \\sum_i w_i y_i,\n",
    "  where w_i's are the weighted-sum weights, and covariance estimator is\n",
    "    cov_{xy} = \\sum_i w_i (x_i - \\mu_x) (y_i - \\mu_y)\n",
    "  with assumption \\sum_i w_i = 1. This covariance estimator is biased, since\n",
    "    E[cov_{xy}] = (1 - \\sum_i w_i ^ 2) Cov(X, Y).\n",
    "  For SSIM measure with unbiased covariance estimators, pass as `compensation`\n",
    "  argument (1 - \\sum_i w_i ^ 2).\n",
    "\n",
    "  Arguments:\n",
    "    x: First set of images.\n",
    "    y: Second set of images.\n",
    "    reducer: Function that computes 'local' averages from the set of images. For\n",
    "      non-convolutional version, this is usually tf.reduce_mean(x, [1, 2]), and\n",
    "      for convolutional version, this is usually tf.nn.avg_pool2d or\n",
    "      tf.nn.conv2d with weighted-sum kernel.\n",
    "    max_val: The dynamic range (i.e., the difference between the maximum\n",
    "      possible allowed value and the minimum allowed value).\n",
    "    compensation: Compensation factor. See above.\n",
    "    k1: Default value 0.01\n",
    "    k2: Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so\n",
    "      it would be better if we took the values in the range of 0 < K2 < 0.4).\n",
    "\n",
    "  Returns:\n",
    "    A pair containing the luminance measure, and the contrast-structure measure.\n",
    "  \"\"\"\n",
    "\n",
    "  c1 = (k1 * max_val)**2\n",
    "  c2 = (k2 * max_val)**2\n",
    "\n",
    "  # SSIM luminance measure is\n",
    "  # (2 * mu_x * mu_y + c1) / (mu_x ** 2 + mu_y ** 2 + c1).\n",
    "  mean0 = reducer(x)\n",
    "  mean1 = reducer(y)\n",
    "  num0 = mean0 * mean1 * 2.0\n",
    "  den0 = math_ops.square(mean0) + math_ops.square(mean1)\n",
    "  luminance = (num0 + c1) / (den0 + c1)\n",
    "\n",
    "  # SSIM contrast-structure measure is\n",
    "  #   (2 * cov_{xy} + c2) / (cov_{xx} + cov_{yy} + c2).\n",
    "  # Note that `reducer` is a weighted sum with weight w_k, \\sum_i w_i = 1, then\n",
    "  #   cov_{xy} = \\sum_i w_i (x_i - \\mu_x) (y_i - \\mu_y)\n",
    "  #          = \\sum_i w_i x_i y_i - (\\sum_i w_i x_i) (\\sum_j w_j y_j).\n",
    "  num1 = reducer(x * y) * 2.0\n",
    "  den1 = reducer(math_ops.square(x) + math_ops.square(y))\n",
    "  c2 *= compensation\n",
    "  cs = (num1 - num0 + c2) / (den1 - den0 + c2)\n",
    "\n",
    "  # SSIM score is the product of the luminance and contrast-structure measures.\n",
    "  return luminance, cs\n",
    "\n",
    "def _fspecial_gauss(size, sigma):\n",
    "  \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function.\"\"\"\n",
    "  size = ops.convert_to_tensor(size, dtypes.int32)\n",
    "  sigma = ops.convert_to_tensor(sigma)\n",
    "\n",
    "  coords = math_ops.cast(math_ops.range(size), sigma.dtype)\n",
    "  coords -= math_ops.cast(size - 1, sigma.dtype) / 2.0\n",
    "\n",
    "  g = math_ops.square(coords)\n",
    "  g *= -0.5 / math_ops.square(sigma)\n",
    "\n",
    "  g = array_ops.reshape(g, shape=[1, -1]) + array_ops.reshape(g, shape=[-1, 1])\n",
    "  g = array_ops.reshape(g, shape=[1, -1])  # For tf.nn.softmax().\n",
    "  g = nn_ops.softmax(g)\n",
    "  return array_ops.reshape(g, shape=[size, size, 1, 1])\n",
    "\n",
    "def _ssim_map_per_channel(img1,\n",
    "                      img2,\n",
    "                      max_val=1.0,\n",
    "                      filter_size=11,\n",
    "                      filter_sigma=1.5,\n",
    "                      k1=0.01,\n",
    "                      k2=0.03,\n",
    "                      keep_padding = True):\n",
    "  \"\"\"Computes SSIM index between img1 and img2 per color channel.\n",
    "\n",
    "  This function matches the standard SSIM implementation from:\n",
    "  Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image\n",
    "  quality assessment: from error visibility to structural similarity. IEEE\n",
    "  transactions on image processing.\n",
    "\n",
    "  Details:\n",
    "    - 11x11 Gaussian filter of width 1.5 is used.\n",
    "    - k1 = 0.01, k2 = 0.03 as in the original paper.\n",
    "\n",
    "  Args:\n",
    "    img1: First image batch.\n",
    "    img2: Second image batch.\n",
    "    max_val: The dynamic range of the images (i.e., the difference between the\n",
    "      maximum the and minimum allowed values).\n",
    "    filter_size: Default value 11 (size of gaussian filter).\n",
    "    filter_sigma: Default value 1.5 (width of gaussian filter).\n",
    "    k1: Default value 0.01\n",
    "    k2: Default value 0.03 (SSIM is less sensitivity to K2 for lower values, so\n",
    "      it would be better if we took the values in the range of 0 < K2 < 0.4).\n",
    "\n",
    "  Returns:\n",
    "    The ssim map for the imgs with a shape like: [..., img_dim_1 - kernel_dim_1 + 1, img_dim_2 - kernel_dim_2 + 1, n_chanels]\n",
    "  \"\"\"\n",
    "  filter_size = constant_op.constant(filter_size, dtype=dtypes.int32)\n",
    "  filter_sigma = constant_op.constant(filter_sigma, dtype=img1.dtype)\n",
    "\n",
    "  shape1, shape2 = array_ops.shape_n([img1, img2])\n",
    "  checks = [\n",
    "      control_flow_ops.Assert(\n",
    "          math_ops.reduce_all(\n",
    "              math_ops.greater_equal(shape1[-3:-1], filter_size)),\n",
    "          [shape1, filter_size],\n",
    "          summarize=8),\n",
    "      control_flow_ops.Assert(\n",
    "          math_ops.reduce_all(\n",
    "              math_ops.greater_equal(shape2[-3:-1], filter_size)),\n",
    "          [shape2, filter_size],\n",
    "          summarize=8)\n",
    "  ]\n",
    "\n",
    "  # Enforce the check to run before computation.\n",
    "  with ops.control_dependencies(checks):\n",
    "    img1 = array_ops.identity(img1)\n",
    "\n",
    "  # TODO(sjhwang): Try to cache kernels and compensation factor.\n",
    "  kernel = _fspecial_gauss(filter_size, filter_sigma)\n",
    "  kernel = array_ops.tile(kernel, multiples=[1, 1, shape1[-1], 1])\n",
    "\n",
    "  # The correct compensation factor is `1.0 - tf.reduce_sum(tf.square(kernel))`,\n",
    "  # but to match MATLAB implementation of MS-SSIM, we use 1.0 instead.\n",
    "  compensation = 1.0\n",
    "\n",
    "  # TODO(sjhwang): Try FFT.\n",
    "  # TODO(sjhwang): Gaussian kernel is separable in space. Consider applying\n",
    "  #   1-by-n and n-by-1 Gaussian filters instead of an n-by-n filter.\n",
    "  def reducer(x):\n",
    "    shape = array_ops.shape(x)\n",
    "    x = array_ops.reshape(x, shape=array_ops.concat([[-1], shape[-3:]], 0))\n",
    "    y = nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1], padding = 'SAME' if keep_padding else 'VALID')\n",
    "    return array_ops.reshape(\n",
    "        y, array_ops.concat([shape[:-3], array_ops.shape(y)[1:]], 0))\n",
    "\n",
    "  luminance, cs = _ssim_helper(img1, img2, reducer, max_val, compensation, k1,\n",
    "                               k2)\n",
    "\n",
    "  ssim_map = luminance*cs\n",
    "\n",
    "  return ssim_map\n",
    "\n",
    "  # Average over the second and the third from the last: height, width.\n",
    "  axes = constant_op.constant([-3, -2], dtype=dtypes.int32)\n",
    "  ssim_val = math_ops.reduce_mean(luminance * cs, axes)\n",
    "  cs = math_ops.reduce_mean(cs, axes)\n",
    "  return ssim_val, cs\n",
    "\n",
    "\n",
    "def get_regions_indexes (magnitude_gradient: tf.Tensor,\n",
    "                         threshold_for_edges: float = 0.12,\n",
    "                         threshold_for_texture: float = 0.06):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  max_gradient_magnitude_per_image = tf.reduce_max(magnitude_gradient, axis = (-1, -2 , -3), keepdims=True)\n",
    "  normalized_magnitude_gradient = magnitude_gradient/max_gradient_magnitude_per_image\n",
    "\n",
    "  edge_indexes = tf.where( normalized_magnitude_gradient >= threshold_for_edges)\n",
    "  texture_indexes = tf.where( tf.math.logical_and( normalized_magnitude_gradient >= threshold_for_texture, normalized_magnitude_gradient < threshold_for_edges) )\n",
    "  smooth_indexes = tf.where( normalized_magnitude_gradient < threshold_for_texture)\n",
    "\n",
    "  return edge_indexes, texture_indexes, smooth_indexes\n",
    "    \n",
    "def three_ssim (original_images,\n",
    "                degraded_images,\n",
    "                max_val=1.0,\n",
    "                weight_for_edges = 2,\n",
    "                weight_for_texture = 1,\n",
    "                weight_for_smooth = 1,\n",
    "                filter_size=11,\n",
    "                filter_sigma=1.5,\n",
    "                k1=0.01,\n",
    "                k2=0.03,\n",
    "                keep_padding = True):\n",
    "  \"\"\"\n",
    "    Computes the SSIM (3-SSIM) modified version described in the article: Content-weighted video quality \n",
    "    assessment using a three-component image model\n",
    "  \"\"\"\n",
    "  ssim_map = _ssim_map_per_channel(original_images, degraded_images, max_val, filter_size, filter_sigma, k1, k2, keep_padding)\n",
    "\n",
    "  img_grad = tf.image.sobel_edges(original_images)\n",
    "  imgs_magnitude_grad = tf.sqrt( tf.square(img_grad[:,:,:,:, 0]) + tf.square(img_grad[:,:,:,:, 1]))\n",
    "\n",
    "  if not keep_padding:\n",
    "    size_decrease = (filter_size - 1)//2\n",
    "    imgs_magnitude_grad = imgs_magnitude_grad[:, size_decrease:-size_decrease, size_decrease:-size_decrease]\n",
    "    print(math_ops.reduce_mean(ssim_map, axis = (-1, -2, -3)))\n",
    "  \n",
    "  edge_indexes, texture_indexes, smooth_indexes = get_regions_indexes (imgs_magnitude_grad, threshold_for_edges = 0.12, threshold_for_texture = 0.06)\n",
    "\n",
    "  zero_map = tf.zeros(shape=imgs_magnitude_grad.shape , dtype = tf.float64)\n",
    "\n",
    "  # Calculate the ssim_map with zeros in diferent regions.\n",
    "\n",
    "  edge_mask = tf.tensor_scatter_nd_update(zero_map, edge_indexes, tf.constant(1., shape = edge_indexes.shape[0], dtype=tf.float64))\n",
    "  ssim_map_for_edges = tf.math.multiply(ssim_map, edge_mask)\n",
    "\n",
    "  texture_mask = tf.tensor_scatter_nd_update(zero_map, texture_indexes, tf.constant(1., shape = texture_indexes.shape[0], dtype=tf.float64))\n",
    "  ssim_map_for_texture = tf.math.multiply(ssim_map, texture_mask)\n",
    "\n",
    "  smooth_mask = tf.tensor_scatter_nd_update(zero_map, smooth_indexes, tf.constant(1., shape = smooth_indexes.shape[0], dtype=tf.float64))\n",
    "  ssim_map_for_smooth = tf.math.multiply(ssim_map, smooth_mask)\n",
    "\n",
    "  ones = edge_mask + texture_mask + smooth_mask\n",
    "  print(tf.reduce_max(ones), tf.reduce_min(ones))\n",
    "\n",
    "  # Calculate the number of nom zero pixels per mask\n",
    "\n",
    "  n_edge_pixels_per_image = tf.reduce_sum(edge_mask, axis = (-1, -2, -3))\n",
    "  n_texture_pixels_per_image = tf.reduce_sum(texture_mask, axis = (-1, -2, -3))\n",
    "  n_smooth_pixels_per_image = tf.reduce_sum(smooth_mask, axis = (-1, -2, -3))\n",
    "\n",
    "  # 3 component calculations\n",
    "\n",
    "  ssim_on_edges = tf.reduce_sum(ssim_map_for_edges, axis = (-1 ,-2, -3))/n_edge_pixels_per_image\n",
    "  ssim_on_textures = tf.reduce_sum(ssim_map_for_texture, axis = (-1 ,-2, -3))/n_texture_pixels_per_image\n",
    "  ssim_on_smooth = tf.reduce_sum(ssim_map_for_smooth, axis = (-1 ,-2, -3))/n_smooth_pixels_per_image\n",
    "  \n",
    "  ssim3 = ( weight_for_edges*n_edge_pixels_per_image*ssim_on_edges + weight_for_texture*n_texture_pixels_per_image*ssim_on_textures + \n",
    "           weight_for_smooth*n_smooth_pixels_per_image*ssim_on_smooth ) / (weight_for_edges*n_edge_pixels_per_image \n",
    "          + weight_for_texture*n_texture_pixels_per_image + weight_for_smooth*n_smooth_pixels_per_image)\n",
    "  \n",
    "  return ssim3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float64) tf.Tensor(1.0, shape=(), dtype=float64)\n",
      "tf.Tensor([0.23340836 0.22501541], shape=(2,), dtype=float64)\n",
      "tf.Tensor([0.08359226 0.07156157], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "img1_np = np.random.normal(127, 25, size = (2,64,64,1))\n",
    "img2_np = np.random.normal(127, 35/3, size = (2,64,64,1))\n",
    "img1 = tf.constant(img1_np, dtype=\"float64\")\n",
    "img2 = tf.constant(img2_np, dtype=\"float64\")\n",
    "\n",
    "print(three_ssim(img1, img2, 255, weight_for_edges=1., weight_for_smooth= 1., weight_for_texture = 1., keep_padding=False))\n",
    "print(tf.image.ssim(img1, img2, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64, 64, 1), dtype=float64, numpy=\n",
       "array([[[[0.67532778],\n",
       "         [0.65899728],\n",
       "         [0.6521072 ],\n",
       "         ...,\n",
       "         [2.        ],\n",
       "         [2.        ],\n",
       "         [2.        ]],\n",
       "\n",
       "        [[0.63145714],\n",
       "         [0.53927537],\n",
       "         [0.45392767],\n",
       "         ...,\n",
       "         [0.53240444],\n",
       "         [0.60048486],\n",
       "         [0.69276183]],\n",
       "\n",
       "        [[0.62823282],\n",
       "         [0.45356033],\n",
       "         [0.26450085],\n",
       "         ...,\n",
       "         [0.34222462],\n",
       "         [0.50108014],\n",
       "         [0.65615168]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.69053757],\n",
       "         [0.55463405],\n",
       "         [0.41501626],\n",
       "         ...,\n",
       "         [0.36821719],\n",
       "         [0.56090262],\n",
       "         [2.        ]],\n",
       "\n",
       "        [[2.        ],\n",
       "         [0.63833916],\n",
       "         [0.57517684],\n",
       "         ...,\n",
       "         [0.60191172],\n",
       "         [0.68441739],\n",
       "         [2.        ]],\n",
       "\n",
       "        [[2.        ],\n",
       "         [2.        ],\n",
       "         [2.        ],\n",
       "         ...,\n",
       "         [2.        ],\n",
       "         [2.        ],\n",
       "         [2.        ]]]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.where(ssim_map > 0.7)\n",
    "\n",
    "tf.tensor_scatter_nd_update(ssim_map, a, tf.constant(2, shape = a.shape[0], dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
       "array([[2],\n",
       "       [3]])>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([1,2,3,4,5])\n",
    "tf.where( tf.math.logical_and( a > 2, a < 5) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Auto2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78e0caa509ae03115ae88a4b08e8fade5e246697214a9f0953a333e2333df42b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
